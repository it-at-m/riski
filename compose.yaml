volumes:
  riskidata:
services:
  db:
    image: docker.io/pgvector/pgvector:pg17@sha256:1a20228d87a48db9587caebaecfdff065268ebe248dafa5f8b447ce3dc96e594
    container_name: pgvector-db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: example_db
    ports:
      - "5432:5432"
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
      - riskidata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5
  adminer:
    image: adminer@sha256:d9498e31999e5622e640b2fe64425099ffbecd3304486b7f343e13ec7c38e7dd
    restart: always
    ports:
      - 8084:8080
  kafka:
    image: apache/kafka:4.1.1@sha256:0bc1bb2478f45b6cea78864df86acdc11e8df2c5172477819a4d12942cbe5d40
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LISTENERS=PLAINTEXT://:9092,PLAINTEXT_INTERNAL://:9094,CONTROLLER://:9093
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:9094
      - KAFKA_BROKER_ID=1
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@localhost:9093
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_MESSAGE_FORMAT_VERSION=2.8-IV0
      - KAFKA_CHECK_CSUMS_IN_COMPACTION=true
      - KAFKA_CHECK_CSUMS_IN_COPYING=true
      # - KAFKA_DISABLE_LOG_MESSAGE_FORMAT_VERSION_CHECK=true
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
    healthcheck:
      test: "/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list"
      interval: 10s
      timeout: 5s
      retries: 10

  redis:
    image: docker.io/redis:8.4@sha256:8ee66466e64f002d69f05c3b61d1cc13f1c310d855a3952b532f798884fac9f6
    deploy:
      resources:
        limits:
          memory: 500M
    command: redis-server /etc/redis.conf
    configs:
      - target: /etc/redis.conf
        source: redis_config
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD-SHELL", "redis-cli ping | grep PONG"]
      interval: 5s
      timeout: 5s
      retries: 5

  # run topic creation with `podman compose --profile init up` or as single service when kafka was already started
  # creates example topic, corresponding dlq and managment topic for group tracking
  topic-init:
    image: docker.io/apache/kafka:4.1.1@sha256:0bc1bb2478f45b6cea78864df86acdc11e8df2c5172477819a4d12942cbe5d40
    profiles: ["init"]
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: >
      sh -c "
        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9094 --create --topic my-topic --partitions 1 --replication-factor 1 || true &&
        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9094 --create --topic my-topic-dlq --partitions 1 --replication-factor 1 || true &&
        /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9094 --create --topic __consumer_offsets --partitions 50 --replication-factor 1 --config cleanup.policy=compact || true
      "
  # run data extraction with `podman compose --profile init up`
  # seeds the database with sample entities and files from the configured RIS endpoint
  extractor:
    build:
      context: .
      dockerfile: riski-extractor/Dockerfile
      args:
        - HTTPS_PROXY=${HTTPS_PROXY}
    profiles: ["init"]
    env_file:
      - ./.env
    depends_on:
      db:
        condition: service_healthy
    restart: "no"

  # run document processing with `podman compose --profile init up`
  # processes file blobs with OCR and stores extracted markdown back to the database
  document-pipeline:
    build:
      context: .
      dockerfile: riski-document-pipeline/Dockerfile
      args:
        - HTTPS_PROXY=${HTTPS_PROXY}
    profiles: ["init"]
    env_file:
      - ./.env
    volumes:
      - ./ca-bundle.crt:/etc/ssl/certs/ca-bundle.crt:ro
    depends_on:
      extractor:
        condition: service_completed_successfully
    restart: "no"

  backend:
    build:
      context: .
      dockerfile: riski-backend/Dockerfile
      args:
        - HTTPS_PROXY=${HTTPS_PROXY}
    env_file:
      - ./.env
    volumes:
      - ./ca-bundle.crt:/etc/ssl/certs/ca-bundle.crt:ro
    ports:
      - "39146:8080"
    networks:
      - internal
    healthcheck:
      test: ["CMD-SHELL", "curl http://localhost:8080/api/healthz"]

  refarch-gateway:
    image: ghcr.io/it-at-m/refarch/refarch-gateway:1.7.0@sha256:3f82ab83c212ca53c9c2b606cfe29291f21525eac86fece215d0e1c6ca51273f
    ports:
      - "8083:8080"
    env_file:
      - ./.env
    environment:
      - ALLOWED_ORIGINS_PUBLIC=http://localhost:*
      - ALLOWED_ORIGINS_CLIENTS=http://localhost:*
      - SPRING_CLOUD_GATEWAY_ROUTES_0_ID=backend
      - SPRING_CLOUD_GATEWAY_ROUTES_0_URI=http://backend:8080/
      - SPRING_CLOUD_GATEWAY_ROUTES_0_PREDICATES_0=Path=/api/**
      - SPRING_CLOUD_GATEWAY_ROUTES_0_FILTERS_0=RewritePath=/api/(?<urlsegments>.*), /api/$\{urlsegments}
      - SPRING_CLOUD_GATEWAY_ROUTES_1_ID=frontend
      - SPRING_CLOUD_GATEWAY_ROUTES_1_URI=http://frontend:8080/
      - SPRING_CLOUD_GATEWAY_ROUTES_1_PREDICATES_0=Path=/**
      - SPRING_PROFILES_ACTIVE=no-security,hazelcast-local
    networks:
      - internal
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD-SHELL", "curl http://localhost:8080/actuator/health/liveness"]
    security_opt: &security_settings
      - no-new-privileges:true

  frontend:
    build:
      context: riski-frontend
      dockerfile: Dockerfile
      args:
        - HTTPS_PROXY=${HTTPS_PROXY}
    ports:
      - "8081:8080"
    networks:
      - internal

networks:
  internal:
configs:
  redis_config:
    content: |
      maxmemory 450mb
      maxmemory-policy allkeys-lru
      save ""
      appendonly yes
      protected-mode no
